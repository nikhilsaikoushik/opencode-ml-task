Task 1: Distance-Based Classification using KNN of Fashion-MNIST

1. Objective
The aim of this task is to understand how distance-based classification works.
In this task, the K-Nearest Neighbors (KNN) algorithm was written from scratch
without using any machine learning libraries.

2. Dataset
The Fashion-MNIST dataset was used.
It contains images of different types of clothes.
There are 10 classes in the dataset.
Each image is of size 28 Ã— 28 pixels.

For faster execution, only part of the dataset was used:
- Training samples: 5000
- Test samples: 500

Each image was converted into numbers by flattening it into a vector of size 784
and normalizing the pixel values.

3. How KNN Works
KNN is a simple algorithm.
There is no training step in KNN.
For every test image, the distance between that image and all training images
is calculated.

The steps are:
1. Calculate the distance between the test image and all training images.
2. Sort the distances from smallest to largest.
3. Choose the K nearest images.
4. Predict the class using majority voting.

4. Distance Used
Two distance methods were used:

- Euclidean distance
- Manhattan distance

These distances help in measuring how similar two images are.

5. Evaluation
The model performance was checked using accuracy.
Accuracy shows how many test images were predicted correctly.

Accuracy = Correct predictions / Total test images

The model was tested using different distance methods and different values of K.
The combination that gave the highest accuracy was selected as the best model.

Some wrong predictions were also printed using class names to understand the
mistakes made by the model.

6. Effect of K
The model was tested with different values of K (1, 3, and 5).

- Small K values can be affected by noise.
- Larger K values give more stable results.

The best K value was chosen based on accuracy.

7. Observations
Some clothes look very similar in the dataset.
Because of this, the model sometimes confused:
- T-shirt and Shirt
- Sneaker and Sandal
- Coat and Pullover

8. Conclusion
In this task, the KNN algorithm was successfully implemented from scratch.
Different distance methods and K values were tested, and the best-performing
model was selected.
This task helped in understanding how distance-based classification works
in a simple and clear way.
